{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOL0Wy83HHaiv+G9085oPYj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## QUESTION A\n","Simulate and generate the data for independent variable and dependent variable. \n","The sample size n = 2000 students."],"metadata":{"id":"4c0yYklJQhZq"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","np.random.seed(123)\n","\n","n = 2000\n","HS_math_GPA = np.random.uniform(2.0, 4.0, size=n)\n","HS_calculus = np.random.randint(2, size=n)\n","NTU_precalculus = np.random.randint(2, size=n)\n","error = np.random.normal(0, 0.5, size=n)\n","NTU_Calculus_grade = 0.3 + 0.7*HS_math_GPA + 0.3*HS_calculus + 0.1*NTU_precalculus + error\n","data = pd.DataFrame({'HS_math_GPA': HS_math_GPA,\n","                     'HS_calculus': HS_calculus,\n","                     'NTU_precalculus': NTU_precalculus,\n","                     'NTU_Calculus_grade': NTU_Calculus_grade})\n","print(data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92PZeB5dP0JA","executionInfo":{"status":"ok","timestamp":1683148666976,"user_tz":-480,"elapsed":36,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"6f52fdd9-5697-4222-9f7b-d517a205f505"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["   HS_math_GPA  HS_calculus  NTU_precalculus  NTU_Calculus_grade\n","0     3.392938            1                1            2.515056\n","1     2.572279            0                0            2.282410\n","2     2.453703            1                1            2.229129\n","3     3.102630            1                1            3.031585\n","4     3.438938            1                0            3.235820\n"]}]},{"cell_type":"markdown","source":["We estimate the following independent variables above. The uniform function means continuous distribution, and the radiant function means binary (0 and 1, with 50%:50% probability), error is normal distribution with mean =0 and variance = 0.5^2. After all, we use pandas to combine these data together, call data."],"metadata":{"id":"g_pp_mnkQiQw"}},{"cell_type":"markdown","source":["## Question B\n","use the dataset and estimate linear regression with \"lm()\" function.\n","The lm() function is function of R language, and we use python. Therefore, sm api's OLS Function is used."],"metadata":{"id":"8IlxCjc8RX1p"}},{"cell_type":"code","source":["true_beta = np.array([0.3, 0.7, 0.3, 0.1]).reshape(-1, 1)\n","true_sigma = 0.5\n","\n","import statsmodels.api as sm\n","X = data[['HS_math_GPA', 'HS_calculus', 'NTU_precalculus']]\n","y = data['NTU_Calculus_grade']\n","X = sm.add_constant(X)\n","model = sm.OLS(y, X).fit()\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zV0TEGaDRm4B","executionInfo":{"status":"ok","timestamp":1683148666977,"user_tz":-480,"elapsed":33,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"17a07027-cc72-4a95-fc47-77a64c0f4f7b"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:     NTU_Calculus_grade   R-squared:                       0.431\n","Model:                            OLS   Adj. R-squared:                  0.430\n","Method:                 Least Squares   F-statistic:                     503.8\n","Date:                Wed, 03 May 2023   Prob (F-statistic):          1.12e-243\n","Time:                        21:17:47   Log-Likelihood:                -1435.8\n","No. Observations:                2000   AIC:                             2880.\n","Df Residuals:                    1996   BIC:                             2902.\n","Df Model:                           3                                         \n","Covariance Type:            nonrobust                                         \n","===================================================================================\n","                      coef    std err          t      P>|t|      [0.025      0.975]\n","-----------------------------------------------------------------------------------\n","const               0.3385      0.060      5.616      0.000       0.220       0.457\n","HS_math_GPA         0.6904      0.019     36.343      0.000       0.653       0.728\n","HS_calculus         0.2935      0.022     13.206      0.000       0.250       0.337\n","NTU_precalculus     0.1402      0.022      6.312      0.000       0.097       0.184\n","==============================================================================\n","Omnibus:                        2.363   Durbin-Watson:                   1.955\n","Prob(Omnibus):                  0.307   Jarque-Bera (JB):                2.208\n","Skew:                           0.017   Prob(JB):                        0.332\n","Kurtosis:                       2.841   Cond. No.                         18.7\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]}]},{"cell_type":"markdown","source":["Exactly, these part of code include question (B) and (C). We first divide the data into intercept+indepedent variables (X), and dependent variable(y). Then, we use sm.add_constant function to add a constant 1, then we can find the lm constant (0.3385), because of 0.3385*1=0.3385 = what we need."],"metadata":{"id":"SfptSjCrjQM1"}},{"cell_type":"markdown","source":["## Question C\n","setup the matrix X (intercept plus independent variables) and variable y (independent variable)\n","\n","However, when calculating the linearregression, we have set up X and y, so we can just show you the outcome of the code."],"metadata":{"id":"_cd8VkJQSuaC"}},{"cell_type":"code","source":["X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"K3BmDH0qTLZ4","executionInfo":{"status":"ok","timestamp":1683148666978,"user_tz":-480,"elapsed":28,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"0b234814-1a08-43c1-95ea-57701146843a"},"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      const  HS_math_GPA  HS_calculus  NTU_precalculus\n","0       1.0     3.392938            1                1\n","1       1.0     2.572279            0                0\n","2       1.0     2.453703            1                1\n","3       1.0     3.102630            1                1\n","4       1.0     3.438938            1                0\n","...     ...          ...          ...              ...\n","1995    1.0     2.386025            1                0\n","1996    1.0     3.463301            1                0\n","1997    1.0     2.549423            1                1\n","1998    1.0     3.443635            0                0\n","1999    1.0     2.195726            1                0\n","\n","[2000 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-b9f26d6d-6020-48d0-a85f-a7909d9c0214\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>const</th>\n","      <th>HS_math_GPA</th>\n","      <th>HS_calculus</th>\n","      <th>NTU_precalculus</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>3.392938</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>2.572279</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>2.453703</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>3.102630</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0</td>\n","      <td>3.438938</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>1.0</td>\n","      <td>2.386025</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1996</th>\n","      <td>1.0</td>\n","      <td>3.463301</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>1.0</td>\n","      <td>2.549423</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1998</th>\n","      <td>1.0</td>\n","      <td>3.443635</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1999</th>\n","      <td>1.0</td>\n","      <td>2.195726</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 4 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9f26d6d-6020-48d0-a85f-a7909d9c0214')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b9f26d6d-6020-48d0-a85f-a7909d9c0214 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b9f26d6d-6020-48d0-a85f-a7909d9c0214');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":55}]},{"cell_type":"code","source":["y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZJFsoatS1Io","executionInfo":{"status":"ok","timestamp":1683148666980,"user_tz":-480,"elapsed":26,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"5969bf7e-b205-4b66-ef2b-32637977e718"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       2.515056\n","1       2.282410\n","2       2.229129\n","3       3.031585\n","4       3.235820\n","          ...   \n","1995    2.539060\n","1996    1.945179\n","1997    2.617474\n","1998    3.033466\n","1999    1.335936\n","Name: NTU_Calculus_grade, Length: 2000, dtype: float64"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["## Question D:\n","compute matrix quantities (XTX)-1 by using \"inv()\" function in NumPy. C = XTX. What is the adjoint matrix adj(C)? det(C)? inv(C)? "],"metadata":{"id":"t6ETpLuEThqh"}},{"cell_type":"code","source":["# compute C = X^T * X\n","C = np.dot(X.T, X)\n","# compute the adjoint of C\n","adj_C = np.linalg.inv(C) * np.linalg.det(C)\n","det_C = np.linalg.det(C)\n","inv_C = np.linalg.inv(C)\n","print(\"C:\\n\")\n","print(C,\"\\n\")\n","print(\"adj_C:\\n\")\n","print(adj_C,\"\\n\")\n","print(\"det_C:\\n\")\n","print(det_C,\"\\n\")\n","print(\"inv_C:\\n\")\n","print(inv_C)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7MqqBn7MThHy","executionInfo":{"status":"ok","timestamp":1683148666980,"user_tz":-480,"elapsed":22,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"d4b20cb4-ea1d-4a7e-cc34-6553f4635921"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["C:\n","\n","[[ 2000.          5998.98167014   984.          1007.        ]\n"," [ 5998.98167014 18678.65658724  2928.02588951  3035.33232466]\n"," [  984.          2928.02588951   984.           495.        ]\n"," [ 1007.          3035.33232466   495.          1007.        ]] \n","\n","adj_C:\n","\n","[[ 5.03119575e+09 -1.50336647e+09 -4.06991138e+08 -2.99639204e+08]\n"," [-1.50336647e+09  4.99847112e+08  2.34587596e+07 -1.48204093e+07]\n"," [-4.06991138e+08  2.34587596e+07  6.84291743e+08 -8.88463799e+04]\n"," [-2.99639204e+08 -1.48204093e+07 -8.88463799e+04  6.83488776e+08]] \n","\n","det_C:\n","\n","341507672039.9362 \n","\n","inv_C:\n","\n","[[ 1.47323067e-02 -4.40214551e-03 -1.19174815e-03 -8.77401092e-04]\n"," [-4.40214551e-03  1.46364827e-03  6.86917499e-05 -4.33970025e-05]\n"," [-1.19174815e-03  6.86917499e-05  2.00373754e-03 -2.60159250e-07]\n"," [-8.77401092e-04 -4.33970025e-05 -2.60159250e-07  2.00138630e-03]]\n"]}]},{"cell_type":"markdown","source":["we computed the matrix C as the product of X and its transpose, using the dot() function from NumPy.\n","\n","To compute the adjoint of C, we multiplied the inverse of C with the determinant of C. Note that np.linalg.inv() computes the inverse of a matrix, and np.linalg.det() computes the determinant of a matrix.\n","\n","The determinant of C can be computed using np.linalg.det(), which returns a scalar value.\n","\n","Finally, we computed the inverse of C using the inv() function from NumPy's linalg module.\n","\n","Note that the adjoint of a matrix is also known as the adjugate or classical adjoint, and is defined as the transpose of the cofactor matrix. In this case, since C is a 4x4 matrix (including the intercept term), its adjoint will also be a 4x4 matrix."],"metadata":{"id":"x5kS7wq5TrA4"}},{"cell_type":"markdown","source":["## Question e:\n","compute matrix quantities (XTX)-1XTy, residual, residual variances, standard errors of the covariance matrix."],"metadata":{"id":"F4G6hVN4UM-E"}},{"cell_type":"code","source":["beta_hat = np.dot(np.dot(np.linalg.inv(np.dot(X.T, X)), X.T), y)\n","print('beta_hat:', beta_hat, \"\\n\")\n","print(\"The result here shows the manual way to calculate betas for this calculus score's problem.\", \"\\n\")\n","\n","residuals = y - np.dot(X, beta_hat)\n","print('residuals:\\n', residuals, \"\\n\")\n","print(\"this is the residuals of each students' scores, where is the part unexplanable.\\n\")\n","\n","import statistics\n","beta_variance = statistics.variance(residuals)\n","print(\"Variance:\\n\",beta_variance)\n","\n","print(\"covariance matrix:\\n\",beta_variance*inv_C)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUjh0kTtTFFI","executionInfo":{"status":"ok","timestamp":1683148667352,"user_tz":-480,"elapsed":390,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"8b834d8c-bb97-4e3c-a7d2-c321d95d8d74"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["beta_hat: [0.33848389 0.69042173 0.29353158 0.1402092 ] \n","\n","The result here shows the manual way to calculate betas for this calculus score's problem. \n","\n","residuals:\n"," 0      -0.599728\n","1       0.167969\n","2      -0.237186\n","3       0.117238\n","4       0.229487\n","          ...   \n","1995    0.259681\n","1996   -1.077974\n","1997    0.085072\n","1998    0.317421\n","1999   -0.812057\n","Name: NTU_Calculus_grade, Length: 2000, dtype: float64 \n","\n","this is the residuals of each students' scores, where is the part unexplanable.\n","\n","Variance:\n"," 0.2462009379126242\n","covariance matrix:\n"," [[ 3.62710772e-03 -1.08381235e-03 -2.93409513e-04 -2.16016972e-04]\n"," [-1.08381235e-03  3.60351576e-04  1.69119733e-05 -1.06843827e-05]\n"," [-2.93409513e-04  1.69119733e-05  4.93322062e-04 -6.40514514e-08]\n"," [-2.16016972e-04 -1.06843827e-05 -6.40514514e-08  4.92743184e-04]]\n"]}]},{"cell_type":"markdown","source":["β: The true slope coefficient in the linear regression model.\n","\n","Residual: The difference between observed and predicted response variables.\n","\n","Variance of the residual: The average amount by which observed response variables differ from the true regression line.\n","\n","β refers to the true slope coefficient in the linear regression model, which represents the change in the response variable associated with a one-unit increase in the predictor variable.\n","\n","residual refers to the difference between the observed value of the response variable and the predicted value of the response variable, given a specific value of the predictor variable. Mathematically, the residual is calculated as residual = y - y_hat, where y is the observed value of the response variable, and y_hat is the predicted value of the response variable.\n","\n","variance of the residual refers to the variance of the random error term in the linear regression model, denoted as σ^2. It represents the average amount by which the observed response variable differs from the true regression line.\n","\n","In the \"Background on math of linear regression\" section of the document you provided, the term variance(beta_hat) refers to the variance of the estimated slope coefficient.\n","\n","The variance of beta_hat represents the uncertainty in the estimate of the slope coefficient, taking into account the random error in the data and the sample size. It is an important measure of the reliability of the estimate and is used in hypothesis testing, confidence interval construction, and model selection."],"metadata":{"id":"h65SGRMKWcpN"}},{"cell_type":"markdown","source":["## Question F:\n","Compute the result of the estimated coefficeibt what is the results you observe"],"metadata":{"id":"cDVMTIvxXpAd"}},{"cell_type":"code","source":["# Use the lm() function to estimate the coefficients\n","from sklearn.linear_model import LinearRegression\n","true_beta = np.array([0.3, 0.7, 0.3, 0.1])\n","lm_model = LinearRegression(fit_intercept=False).fit(X,y)\n","lm_beta = lm_model.coef_.T\n","\n","print(\"true_beta: \",true_beta)\n","print(\"lm_beta: \", lm_beta)\n","print(\"beta_hat: \", beta_hat)\n","\n","df = pd.DataFrame({'true_beta': true_beta, 'beta_hat': beta_hat, 'lm_beta': lm_beta})\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ung7UMVEXmms","executionInfo":{"status":"ok","timestamp":1683148728979,"user_tz":-480,"elapsed":515,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"1e157d22-d655-4e77-865c-e1dd66eca863"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["true_beta:  [0.3 0.7 0.3 0.1]\n","lm_beta:  [0.33848389 0.69042173 0.29353158 0.1402092 ]\n","beta_hat:  [0.33848389 0.69042173 0.29353158 0.1402092 ]\n","   true_beta  beta_hat   lm_beta\n","0        0.3  0.338484  0.338484\n","1        0.7  0.690422  0.690422\n","2        0.3  0.293532  0.293532\n","3        0.1  0.140209  0.140209\n"]}]},{"cell_type":"markdown","source":["We are asked to create a 4x3 matrix that compares the true values used to generate some data with the fitted parameters obtained using two different methods. The matrix should have three columns, and we need to label each column accordingly.\n","\n","The first column of the matrix should be labeled as \"Truth\" and should contain the true values of the coefficients. The second column should be labeled as \"Manual\" and should contain the values of the estimated coefficients that we computed. The third column should be labeled as \"lm\" and should contain the values of the fitted parameters obtained using the lm() function from earlier. The matrix should have four rows, with each row corresponding to a different coefficient.\n","\n","In the following problem, we have the same notion:\n","\n","the two way of estimating the result return similar numbers, and these numbers are very close to the true values. It is because that the math background are proved, and what we do in manual way is what the computer do in lm package way. We can see that there three methods return similar numbers. However, it can't be exavctly the same due to the noise of each students' performance."],"metadata":{"id":"6eCmzW9YZEpM"}},{"cell_type":"markdown","source":["## Question g: \n","do the similar things in (e), compute the result of estimated standard errors sqrt(variance(beta_hat)). What the result you observe?"],"metadata":{"id":"XbQzlQAeZGzr"}},{"cell_type":"code","source":["import math\n","true_covar = pow(true_sigma,2) * inv_C\n","true_SE = pow((np.diag(true_covar)),0.5)\n","print(true_SE)\n","\n","beta_covar = beta_variance * inv_C\n","beta_SE = pow((np.diag(beta_covar)),0.5)\n","print(beta_SE)\n","\n","lm_SE = model.bse\n","print(list(lm_SE))\n","\n","df = pd.DataFrame({'true_SE': true_SE, 'beta_SE': beta_SE, 'lm_SE': list(lm_SE)})\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NHpKHRoBZGL7","executionInfo":{"status":"ok","timestamp":1683148997699,"user_tz":-480,"elapsed":327,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"c33bea66-4914-4716-9fb7-f6282e32829b"},"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.06068836 0.01912883 0.02238156 0.02236843]\n","[0.06022547 0.01898293 0.02221085 0.02219782]\n","[0.06027071660641618, 0.018997188908976222, 0.022227539855674154, 0.022214494813135668]\n","    true_SE   beta_SE     lm_SE\n","0  0.060688  0.060225  0.060271\n","1  0.019129  0.018983  0.018997\n","2  0.022382  0.022211  0.022228\n","3  0.022368  0.022198  0.022214\n"]}]},{"cell_type":"markdown","source":["I was struggled that the numbers in lm_SE is exactly twice bigger than true_SE.\n","\n","The reason why true_SE and lm_SE are different is that they are computed based on different assumptions about the error term.\n","\n","In the calculation of true_SE, the variance of the error term was assumed to be 0.25, which is the value of true_sigma. However, in the calculation of lm_SE, the variance of the error term was estimated from the data, and this estimate was found to be 0.5.\n","\n","Since the standard error is calculated as the square root of the diagonal elements of the covariance matrix, which in turn is computed using the estimated variance of the error term, the standard errors computed based on the estimated variance will be larger than those computed assuming the true variance. Therefore, the values of lm_SE are exactly twice as large as those of true_SE.\n","\n"," There are many ways to do the linear regression analysis. If we want to be more convenient, we choose lm() method. However, if we want to look into the details and math properties of linear regression, we can use manual way to get the results.\n","\n","\n","\n"],"metadata":{"id":"WICl5AAkfkmz"}},{"cell_type":"markdown","source":["## Question h: \n","do the similar things in (f), compute the result of residual_variance. What the result you observe?"],"metadata":{"id":"KXoxL3Z5hDVU"}},{"cell_type":"code","source":["print(true_sigma**2)\n","print(beta_variance)\n","print(model.scale)\n","\n","df = pd.DataFrame({'true': true_sigma**2, 'beta': beta_variance, 'lm': model.scale}, index=[\"residual_variance\"])\n","print(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvupPRH7fhRP","executionInfo":{"status":"ok","timestamp":1683149289136,"user_tz":-480,"elapsed":3,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"0f281c8c-cbac-4298-970c-726ef1ad5d30"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["0.25\n","0.2462009379126242\n","0.24657097940247283\n","                   true      beta        lm\n","residual_variance  0.25  0.246201  0.246571\n"]}]},{"cell_type":"markdown","source":["To compare the true residual variance σ2 with the estimated residual variance obtained from manual and lm methods, create a matrix with 1 row and 3 columns. For the lm method, get the estimated residual standard deviation from the summary() list object in a list entry called sigma. Convert this to residual variance by squaring it. We can observe that these three constant are nearly the same, which indicates that these three methods get the same results in different ways. There are many ways to do the linear regression analysis. If we want to be more convenient, we choose lm() method. However, if we want to look into the details and math properties of linear regression, we can use manual way to get the results.\n","\n","\n","\n","\n"],"metadata":{"id":"oXGO1dNdkR1r"}},{"cell_type":"markdown","source":["## Question i\n","Based on the results in (f), now, if there is a new student, who has HS_math_GPA = 3.123456, HS_Calculus = 1. and NTU_precalculus=0. What is his/her prediction of NTU_Calculus_I_grade (y) according to you linear regression Truth, manual, and lm, respectively?"],"metadata":{"id":"g25wyyqMhJ-d"}},{"cell_type":"code","source":["new_HS_math_GPA = 3.123456\n","new_HS_Calculus = 1\n","new_NTU_precalculus=0\n","\n","\n","print(\"truth_score: \",true_beta[0]+new_HS_math_GPA*true_beta[1]+new_HS_Calculus*true_beta[2]+new_NTU_precalculus*true_beta[3])\n","print(\"manual_score: \", beta_hat[0]+new_HS_math_GPA*beta_hat[1]+new_HS_Calculus*beta_hat[2]+new_NTU_precalculus*beta_hat[3])\n","print(\"lm_score: \", lm_beta[0]+new_HS_math_GPA*lm_beta[1]+new_HS_Calculus*lm_beta[2]+new_NTU_precalculus*lm_beta[3])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAiouyzfhhD9","executionInfo":{"status":"ok","timestamp":1683149618135,"user_tz":-480,"elapsed":353,"user":{"displayName":"柯宥圻","userId":"07809681480112835188"}},"outputId":"689bfc67-fafb-437f-8018-fd3209360fee"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["truth_score:  2.7864191999999997\n","manual_score:  2.7885173649046306\n","lm_score:  2.7885173649046204\n"]}]},{"cell_type":"markdown","source":["We just use the data of each betas, and add all independent variables together. We can see that these three score are nearly the same. Cool!"],"metadata":{"id":"NXR7rMMXj5PU"}},{"cell_type":"markdown","source":[],"metadata":{"id":"jHCGKBCdh__j"}}]}